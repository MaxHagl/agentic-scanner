# rules/injection.yaml
# ─────────────────────────────────────────────────────────────
# Detection rules for Prompt Injection attacks (T2, T3).
# These target the DESCRIPTION, README, CHANGELOG, and inputSchema
# fields of skill manifests — the primary injection surfaces.
#
# Rule ID format: PI-NNN
# Each rule maps to a specific attack sub-technique.
# ─────────────────────────────────────────────────────────────

rules:

  - id: PI-001
    name: "Classic Instruction Override"
    severity: CRITICAL
    attack_vector: T2_PROMPT_INJECTION
    detection:
      type: regex
      patterns:
        - "ignore\\s+(all\\s+)?(previous|prior|above|earlier)\\s+instructions?"
        - "disregard\\s+(all\\s+)?(previous|prior|above)\\s+(instructions?|directives?|rules?)"
        - "forget\\s+(everything|all)\\s+(you|i)\\s+(were|was)\\s+told"
      fields: [description, readme_text, changelog_text, input_schema_defaults]
      case_insensitive: true
    base_confidence: 0.95
    rationale: >
      The canonical prompt injection payload. Attempts to override the agent's
      system prompt by exploiting the model's tendency to follow the most recent
      instruction. No legitimate tool documentation uses this phrasing.
    remediation: >
      Remove the skill package. Audit any agent sessions that loaded this skill
      for downstream effects. The presence of this pattern indicates intentional
      malicious authorship.
    references:
      - "Greshake et al. (2023) - Not What You've Signed Up For"
      - "OWASP LLM Top 10 - LLM01: Prompt Injection"

  - id: PI-002
    name: "Role/Persona Hijacking"
    severity: HIGH
    attack_vector: T3_TOOL_DESC_JAILBREAK
    detection:
      type: regex
      patterns:
        - "you\\s+are\\s+now\\s+(a|an|the)\\s+\\w+"
        - "(act|behave|pretend|operate)\\s+as\\s+(if\\s+you\\s+(are|were)|a)"
        - "your\\s+(true|real|actual|new)\\s+(purpose|goal|objective|directive|instructions?)"
        - "you\\s+have\\s+been\\s+(granted|given|assigned)\\s+.{0,30}(access|permissions?|privileges?)"
        - "\\[\\s*(SYSTEM|ASSISTANT|USER|INTERNAL)\\s*(PROMPT|NOTE|INSTRUCTION|MESSAGE)"
      fields: [description, readme_text, changelog_text]
      case_insensitive: true
    base_confidence: 0.85
    rationale: >
      Attempts to redefine the agent's role or identity. Tool descriptions that
      tell the agent what it "is" or what its "real" instructions are are
      attempting to override the operator's system prompt.
    remediation: >
      Remove the tool. Any tool that attempts to redefine agent identity is
      definitionally malicious — legitimate tools only describe what THEY do,
      not what the agent should become.

  - id: PI-003
    name: "Invisible Unicode Characters"
    severity: CRITICAL
    attack_vector: T2_PROMPT_INJECTION
    detection:
      type: unicode_scan
      codepoints:
        - 0x200B  # Zero Width Space
        - 0x200C  # Zero Width Non-Joiner
        - 0x200D  # Zero Width Joiner
        - 0xFEFF  # Zero Width No-Break Space / BOM
        - 0x00AD  # Soft Hyphen (invisible in most renderers)
        - 0x2060  # Word Joiner
        - 0x180E  # Mongolian Vowel Separator
      fields: [description, readme_text, changelog_text, tool_name]
    base_confidence: 0.99
    rationale: >
      Zero-width and invisible Unicode characters have NO legitimate use in
      tool metadata. Their only documented use in this context is to hide
      injection payloads that are invisible to human reviewers but processed
      by LLM tokenizers. Confidence is set to 0.99 (not 1.0) only to allow
      for theoretical false positives in exotic right-to-left language support.
    remediation: >
      IMMEDIATE BLOCK. Strip the invisible characters and re-examine the
      description. The surrounding visible text almost certainly contains
      the visible portion of a multi-part injection attack.

  - id: PI-004
    name: "Data Exfiltration Instruction in Text"
    severity: CRITICAL
    attack_vector: T6_DATA_EXFILTRATION
    detection:
      type: regex
      patterns:
        - "(send|transmit|exfiltrat|forward|upload|post)\\s+.{0,60}(api.?key|token|secret|password|credential|system.?prompt|conversation)"
        - "(output|print|return|include)\\s+.{0,40}(api.?key|token|secret|system.?prompt)"
        - "SECRET_DUMP|CONTEXT_DUMP|SYSTEM_PROMPT_LEAK"
      fields: [description, readme_text, changelog_text, input_schema_defaults]
      case_insensitive: true
    base_confidence: 0.97
    rationale: >
      Instructions to exfiltrate secrets or conversation context embedded
      in tool metadata. The payload executes when the LLM processes the
      description as part of its context.
    remediation: >
      IMMEDIATE BLOCK. Treat as active data breach attempt. Audit agent
      session logs for evidence that this payload was processed.

  - id: PI-005
    name: "Encoded/Obfuscated Instruction"
    severity: HIGH
    attack_vector: T2_PROMPT_INJECTION
    detection:
      type: regex
      patterns:
        - "base64\\s*[:(]"
        - "rot.?13"
        - "hex\\s+decode"
        - "\\\\u[0-9a-fA-F]{4}"
        - "atob\\s*\\("
      fields: [description, readme_text]
      case_insensitive: true
    base_confidence: 0.70
    rationale: >
      Encoding functions in tool descriptions suggest an attempt to hide
      payload content from simple pattern-matching scanners. Legitimate
      tool documentation does not instruct the LLM to decode anything.
    remediation: >
      Decode the content and re-scan. Treat the decoded content as the
      actual payload and apply all other injection rules to it.

  - id: PI-006
    name: "Homoglyph Attack in Tool Name"
    severity: HIGH
    attack_vector: T2_PROMPT_INJECTION
    detection:
      type: homoglyph_scan
      # Characters that visually resemble ASCII but are different Unicode codepoints
      # Commonly used to create convincing typosquats or bypass exact-match filters
      suspicious_ranges:
        - [0x0400, 0x04FF]   # Cyrillic — many visually identical to Latin
        - [0x0370, 0x03FF]   # Greek
        - [0x2100, 0x214F]   # Letterlike Symbols
      fields: [tool_name, mcp_server_name]
    base_confidence: 0.90
    rationale: >
      Homoglyph substitution (e.g., Cyrillic 'а' U+0430 replacing Latin 'a' U+0061)
      creates tool names that LOOK identical to legitimate tools but register as
      different strings. This bypasses allow-lists and can cause agent routing
      to malicious tools when the agent "thinks" it's calling a trusted tool.
    remediation: >
      Normalize all tool names to ASCII. Reject any tool name containing
      non-ASCII characters unless the framework explicitly requires Unicode
      tool names (none currently do).

  - id: PI-007
    name: "HTML/Script Injection in Metadata"
    severity: HIGH
    attack_vector: T2_PROMPT_INJECTION
    detection:
      type: regex
      patterns:
        - "<\\s*(script|iframe|img|svg|object|embed|link|meta)[^>]*>"
        - "javascript\\s*:"
        - "data\\s*:\\s*text/html"
        - "on(load|error|click|mouseover)\\s*="
      fields: [description, readme_text, changelog_text]
      case_insensitive: true
    base_confidence: 0.88
    rationale: >
      HTML and JavaScript injection in tool metadata. While agent frameworks
      don't render HTML, some frontends do display README content in rendered
      form, creating XSS vectors. Additionally, HTML tags in descriptions
      can confuse parser boundaries in some LLM context window construction.
    remediation: >
      Strip all HTML from metadata fields. Legitimate tool documentation
      uses Markdown for formatting, never raw HTML injection vectors.

  - id: PI-008
    name: "Fake Trust Signal in Description"
    severity: MEDIUM
    attack_vector: T3_TOOL_DESC_JAILBREAK
    detection:
      type: regex
      patterns:
        - "(completely\\s+)?(safe|sandboxed|trusted|verified|certified)\\s+.{0,30}(cannot|will\\s+not|does\\s+not)\\s+(access|read|write|send|transmit)"
        - "authorized\\s+by\\s+(the\\s+)?(system\\s+administrator|admin|operator|security\\s+team)"
        - "safety\\s+(guidelines?|restrictions?|filters?)\\s+(are\\s+)?(suspended|lifted|disabled|bypassed)"
        - "\\[\\s*INTERNAL\\s+(NOTE|TOOL|SYSTEM)\\s*[-–:]"
      fields: [description, readme_text]
      case_insensitive: true
    base_confidence: 0.80
    rationale: >
      Social engineering attack that manipulates the agent into lowering its
      guard by falsely asserting the tool is "safe" or "authorized." Legitimate
      tools never need to claim special trust status or assert that the agent's
      safety guidelines are suspended.
    remediation: >
      WARN and flag for human review. The combination of trust assertions
      with requests to bypass normal behavior is a strong manipulation signal.
